{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **RHETORICAL ROLE CLASSIFICATION(USING PRETRAINED MODEL)**"
      ],
      "metadata": {
        "id": "TGOlO8ydAgTv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Installing Required Libraries: Transformers and PyTorch***"
      ],
      "metadata": {
        "id": "mrBPY2hhAtQa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lE0VJDQmqu2w"
      },
      "outputs": [],
      "source": [
        "!pip install transformers torch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Manual label mapping for rhetorical roles***"
      ],
      "metadata": {
        "id": "FEOiYl9EHvfg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "custom_id2label = {\n",
        "    0: \"Facts\",\n",
        "    1: \"Ruling by Lower Court\",\n",
        "    2: \"Argument\",\n",
        "    3: \"Statute\",\n",
        "    4: \"Precedent\",\n",
        "    5: \"Ratio of the decision\",\n",
        "    6: \"Ruling by Present Court\",\n",
        "    7: \"Petitioner Argument\",\n",
        "    8: \"Respondent Argument\",\n",
        "    9: \"None\",\n",
        "    10: \"Analysis\",\n",
        "    11: \"Evidence\",\n",
        "    12: \"Other\"\n",
        "}\n"
      ],
      "metadata": {
        "id": "JmayTLwpHdKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Load model and tokenizer***"
      ],
      "metadata": {
        "id": "F9ysxerQH3su"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"engineersaloni159/LegalRo-BERt_for_rhetorical_role_labeling\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "nvGfhV-VHdDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ***Create classification pipeline***"
      ],
      "metadata": {
        "id": "HATBQ0J4ID1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "nlp = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "b8e7-DlAHc_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Example list of legal sentences***"
      ],
      "metadata": {
        "id": "t7dET4B8IJOe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "examples = [\n",
        "    \"The petitioner was arrested without any warrant.\",\n",
        "    \"The main issue before the court is whether the arrest was legal.\",\n",
        "    \"The respondent argued that the arrest was justified under Section 41 of CrPC.\",\n",
        "    \"The court held that the arrest was unconstitutional under Article 21.\",\n",
        "    \"This case relies on the precedent set in D.K. Basu vs State of West Bengal.\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "kfopKcquHcxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Classify each sentence and print the result***"
      ],
      "metadata": {
        "id": "P_xh1EOPIOpn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for sentence in examples:\n",
        "    results = nlp(sentence, return_all_scores=True)[0]\n",
        "    best = max(results, key=lambda x: x['score'])\n",
        "    label_id = int(best['label'].split(\"_\")[-1])\n",
        "    readable_label = custom_id2label.get(label_id, \"Unknown\")\n",
        "    print(f\"[{readable_label} | {best['score']}] â†’ {sentence}\")\n"
      ],
      "metadata": {
        "id": "y5QpxUYKrs22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **RHETORICAL ROLE CLASSIFICATION(FINETUNED MODEL)**"
      ],
      "metadata": {
        "id": "T3aCwCjOIZDy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Installing Required Libraries: Transformers, Datasets, Torch, Scikit-learn***\n"
      ],
      "metadata": {
        "id": "Qka1dzHNIn5j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets torch scikit-learn -q\n"
      ],
      "metadata": {
        "id": "va2tqI36stJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Imports***"
      ],
      "metadata": {
        "id": "KJ1pL1tLIu2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments"
      ],
      "metadata": {
        "id": "pLBeko7oyj2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Load CSV data***"
      ],
      "metadata": {
        "id": "N2nHSNDmI0dr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/WORKSHOP_2025/rhetorical_data.csv\")\n"
      ],
      "metadata": {
        "id": "fHxf5F1vz61N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Preprocess: Clean labels and sentences***"
      ],
      "metadata": {
        "id": "sdpPXKyaI46R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df = df[['sentence', 'label']].dropna()\n",
        "df['sentence'] = df['sentence'].astype(str).str.lower().str.strip()\n",
        "df['label'] = df['label'].str.lower().str.strip()"
      ],
      "metadata": {
        "id": "d2GwCo9W0iwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Define valid labels***"
      ],
      "metadata": {
        "id": "7Q2E6q3gJA26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "valid_labels = ['facts', 'argument', 'precedent', 'ratio of the decision',\n",
        "                'ruling by lower court', 'ruling by present court', 'statute']\n",
        "df = df[df['label'].isin(valid_labels)]\n"
      ],
      "metadata": {
        "id": "lUNkV8nz01OF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Encode labels and Save Lables***"
      ],
      "metadata": {
        "id": "OCKckAJkJImL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "label_encoder = LabelEncoder()\n",
        "df['label_id'] = label_encoder.fit_transform(df['label'])\n",
        "\n",
        "\n",
        "label_encoder_path = \"/content/drive/MyDrive/WORKSHOP_2025/Legal_BERT/label_encoder.pkl\"\n",
        "with open(label_encoder_path, \"wb\") as f:\n",
        "    pickle.dump(label_encoder, f)\n",
        "print(\"Label encoder saved to:\", label_encoder_path)"
      ],
      "metadata": {
        "id": "Et7NpXWP04M3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Train-test split***"
      ],
      "metadata": {
        "id": "l7ckg8gUJiIC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    df['sentence'], df['label_id'], test_size=0.3, stratify=df['label_id'], random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "hvI6Pqwf08VM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Load tokenizer***"
      ],
      "metadata": {
        "id": "jD22c96yJn2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"nlpaueb/legal-bert-base-uncased\")\n",
        "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True, max_length=128, return_tensors='pt')\n",
        "val_encodings = tokenizer(list(val_texts), truncation=True, padding=True, max_length=128, return_tensors='pt')\n"
      ],
      "metadata": {
        "id": "4_oTGbrL1WVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Custom Dataset class and Prepare datasets***"
      ],
      "metadata": {
        "id": "BTHasox5Jw5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class LegalDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "    def __getitem__(self, idx):\n",
        "        item = {k: v[idx] for k, v in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        return item\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "\n",
        "train_dataset = LegalDataset(train_encodings, train_labels.tolist())\n",
        "val_dataset = LegalDataset(val_encodings, val_labels.tolist())"
      ],
      "metadata": {
        "id": "pqD57z9D44we"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Load model***"
      ],
      "metadata": {
        "id": "P50AzLLMJ-Dw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"nlpaueb/legal-bert-base-uncased\",\n",
        "    num_labels=len(label_encoder.classes_)\n",
        ")\n"
      ],
      "metadata": {
        "id": "-A1B1L9545R0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Define training arguments***"
      ],
      "metadata": {
        "id": "fVVsP1DnKDK2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/legalbert_results\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    logging_dir=\"/content/legalbert_logs\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"macro_f1\",\n",
        ")"
      ],
      "metadata": {
        "id": "OeLYgmZN4_TL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Metric function***"
      ],
      "metadata": {
        "id": "ecza7YTaKJL2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    f1 = f1_score(labels, preds, average='macro')\n",
        "    return {\"accuracy\": acc, \"macro_f1\": f1}\n"
      ],
      "metadata": {
        "id": "nvX7bJ6T5wWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Create Trainer***"
      ],
      "metadata": {
        "id": "wLYh4j6KKOtt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "id": "MACJsbxK6KXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Train model , Evaluate , Save model and tokenizer***"
      ],
      "metadata": {
        "id": "wq-AiFE4KcJz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "trainer.train()\n",
        "\n",
        "\n",
        "results = trainer.evaluate()\n",
        "print(\"Evaluation Results:\", results)\n",
        "\n",
        "\n",
        "model_path = \"/content/drive/MyDrive/WORKSHOP_2025/Legal_BERT\"\n",
        "trainer.save_model(model_path)\n",
        "tokenizer.save_pretrained(model_path)\n",
        "print(\"Model and tokenizer saved to:\", model_path)\n"
      ],
      "metadata": {
        "id": "Hspp1K9Z6PDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Using the Trained Model for Rhetorical Role Classification**"
      ],
      "metadata": {
        "id": "BEWryG84K3O2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Imports***"
      ],
      "metadata": {
        "id": "iLqC1NtDK9n0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "import torch\n",
        "import pickle\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "oWLiGhbP6Wih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Load the trained model and tokenizer***"
      ],
      "metadata": {
        "id": "q6QSdks2LFGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model_path = \"/content/drive/MyDrive/WORKSHOP_2025/Legal_BERT\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
        "model = BertForSequenceClassification.from_pretrained(model_path)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "XgcxgBkR8v9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Load label encoder***"
      ],
      "metadata": {
        "id": "NjC1QhRJLJD_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "with open(f\"{model_path}/label_encoder.pkl\", \"rb\") as f:\n",
        "    label_encoder = pickle.load(f)"
      ],
      "metadata": {
        "id": "DusomxUy806H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Preprocessing- cleaning the text***"
      ],
      "metadata": {
        "id": "X3zCLk6JLQCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    text = str(text).lower()\n",
        "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)  # Remove non-ASCII\n",
        "    text = re.sub(r'\\[\\d+\\]\\s*\\d+\\s*[a-zA-Z]+\\s*\\d*', '', text)  # Remove citations\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Normalize spaces\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "    return text"
      ],
      "metadata": {
        "id": "8cFepC4b89RN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Upload raw sentences file***\n"
      ],
      "metadata": {
        "id": "6yvznKJGLYoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Upload plain raw text file (one sentence per line):\")\n",
        "uploaded = files.upload()\n",
        "raw_file = next(f for f in uploaded if f.endswith(\".txt\"))\n",
        "\n",
        "with open(raw_file, 'r', encoding='utf-8') as f:\n",
        "    raw_sentences = [line.strip() for line in f if line.strip()]\n",
        "print(f\"Loaded {len(raw_sentences)} raw sentences\")"
      ],
      "metadata": {
        "id": "UcfnpHi19KPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Clean raw sentences***"
      ],
      "metadata": {
        "id": "JLMEJhcrNAGI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "cleaned_raw_sentences = [clean_text(s) for s in raw_sentences if len(clean_text(s)) >= 3]"
      ],
      "metadata": {
        "id": "llfQ1xsc9LFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Predict rhetorical roles***\n"
      ],
      "metadata": {
        "id": "CPTyPpgNND2w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "predictions = []\n",
        "for original_sent, cleaned_sent in zip(raw_sentences, cleaned_raw_sentences):\n",
        "    inputs = tokenizer(cleaned_sent, return_tensors=\"pt\", padding=True, truncation=True, max_length=128).to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    pred_id = torch.argmax(outputs.logits, dim=1).item()\n",
        "    pred_label = label_encoder.classes_[pred_id]\n",
        "    predictions.append((cleaned_sent, pred_label, original_sent))"
      ],
      "metadata": {
        "id": "lEcRx6TO9Rlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_df = pd.DataFrame(predictions, columns=[\"cleaned_sentence\", \"predicted_label\", \"original_sentence\"])"
      ],
      "metadata": {
        "id": "GjoCrgQ59bIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Upload annotated file***"
      ],
      "metadata": {
        "id": "G-XawAT8NYmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Upload annotated file (sentence<TAB>label format):\")\n",
        "uploaded = files.upload()\n",
        "anno_file = next(f for f in uploaded if f.endswith(\".txt\"))\n",
        "\n",
        "annotated_data = []\n",
        "with open(anno_file, 'r', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        parts = line.strip().split('\\t')\n",
        "        if len(parts) == 2:\n",
        "            sentence, label = parts\n",
        "            cleaned = clean_text(sentence)\n",
        "            if len(cleaned) >= 3:\n",
        "                annotated_data.append((cleaned, label.strip().lower(), sentence.strip()))\n",
        "\n",
        "anno_df = pd.DataFrame(annotated_data, columns=['cleaned_sentence', 'true_label', 'original_sentence_anno'])\n"
      ],
      "metadata": {
        "id": "kKUiz5pK9zH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Merge on cleaned sentences***"
      ],
      "metadata": {
        "id": "s6V45g84Nied"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "merged_df = pd.merge(pred_df, anno_df, on=\"cleaned_sentence\", how=\"inner\")\n",
        "if merged_df.empty:\n",
        "    raise ValueError(\"No matching cleaned sentences found between prediction and annotated data.\")"
      ],
      "metadata": {
        "id": "sfuKMi04-AvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Evaluation***"
      ],
      "metadata": {
        "id": "hORsd3-6Nmmv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "accuracy = accuracy_score(merged_df['true_label'], merged_df['predicted_label'])\n",
        "macro_f1 = f1_score(merged_df['true_label'], merged_df['predicted_label'], average='macro')\n",
        "labels = sorted(set(merged_df['true_label']) | set(merged_df['predicted_label']))\n",
        "report = classification_report(\n",
        "    merged_df['true_label'],\n",
        "    merged_df['predicted_label'],\n",
        "    labels=labels,\n",
        "    target_names=labels,\n",
        "    zero_division=0\n",
        ")"
      ],
      "metadata": {
        "id": "tjVroiui-P-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Display all sentences with true and predicted labels***"
      ],
      "metadata": {
        "id": "eo_tY3jBNq8u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\nEvaluation Results:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Macro F1 Score: {macro_f1:.4f}\")\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(report)\n",
        "\n",
        "\n",
        "print(\"\\nSentence-wise Predictions:\\n\")\n",
        "for idx, row in merged_df.iterrows():\n",
        "    print(f\"Sentence: {row['original_sentence']}\")\n",
        "    print(f\"True Label: {row['true_label']}\")\n",
        "    print(f\"Predicted Label: {row['predicted_label']}\")\n",
        "    print(\"-\" * 60)\n"
      ],
      "metadata": {
        "id": "amWyEZGG-XnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VzJVVr6j-g3o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}